# k-近邻算法，属于分类算法

@[机器学习]

> 工作原理：
存在一个样本数据集合（训练样本集），样本集中每个数据都存在标签（对应的分类）。
输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，
然后算法提取样本集中特征最相似数据（最近邻）的分类标签。

一般只取前k个最相似的数据，出现次数最多的分类作为新数据的分类。

通常k是不大于20的整数。

- 优点：精度高、对异常值不敏感、无数据输入假定。
- 缺点：计算复杂度高、空间复杂度高。
- 适用数据范围：数值型和标称型。



伪代码：
对未知类别属性的数据集中的每个点依次执行一下操作：
1. 计算已知类别属性的数据集中的点与当前之间的距离；
2. 按照距离递增次序排序；
3. 选取与当前点距离最小的k个点；
4. 确定前k个点所在的类别的出现频率；
5. 返回前k个点出现频率最高的类别作为当前点的预测分类。

Python 3.X 示例代码另见knn.py

----------

## 函数说明：

- knn_classify(inX, dataSet, labels, k)

  本算法的核心

  参数说明：

  inX：待分类的特征向量

  dataSet：训练样本集

  labels：训练样本对应的分类标签

  k：选择最近邻的数目




- loadDataSet(path)

  加载数据集
  
  在实验中，采用的是 IRIS数据集

  返回两个numpy的array对象，分别是特征集合以及对应的分类标签

- autoNorm(dataSet)

  特征归一化，将特征值转化为0到1区间内的值

  newValue = (oldValue - min) / (max - min)

- def showDataSet(dataSet, labels)

  展示数据集，在这里只是将数据集的第0和第3个特征作为x/y轴，绘制成散点图

  从结果可以看出，不同分类之间的数据呈现出区别

- text2num(labels)

  将文本标签转化为数字

  Iris-setosa     对应类别1

  Iris-versicolor 对应类别2

  Iris-virginica  对应类别3


